{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('..')\n",
    "import zsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = 'ResNet101'\n",
    "ds = zsl.data.AwAFeaturesDataset(\n",
    "    '../data/AwA2/Animals_with_Attributes2',\n",
    "    features_type=fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antelope\n",
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "features, target, semantic = ds[0]\n",
    "print(ds.classes[target])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = zsl.data.AwAFeaturesDataset(\n",
    "    '../data/AwA2/Animals_with_Attributes2',\n",
    "    features_type=fe,\n",
    "    load_unseen=False)\n",
    "\n",
    "valid_ds = zsl.data.AwAFeaturesDataset(\n",
    "    '../data/AwA2/Animals_with_Attributes2',\n",
    "    features_type=fe,\n",
    "    load_unseen=True,\n",
    "    load_only_unseen=True)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds, \n",
    "    shuffle=True, \n",
    "    batch_size=64,\n",
    "    collate_fn=zsl.utils.collate_image_folder)\n",
    "\n",
    "valid_dl = DataLoader(\n",
    "    valid_ds, \n",
    "    batch_size=32,\n",
    "    collate_fn=zsl.utils.collate_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7913, 29409)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_unit = zsl.models.LinearSemanticUnit(\n",
    "    in_features=len(train_ds.attrs),\n",
    "    out_features=1024)\n",
    "visual_fe = zsl.models.Identity(features.size(0))                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic repr shape: torch.Size([1, 1024])\n",
      "Visual embedding shape: torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "semantic = torch.FloatTensor(semantic)\n",
    "print('Semantic repr shape:', semantic_unit(semantic.unsqueeze(0)).size())\n",
    "print('Visual embedding shape:', visual_fe(features.unsqueeze(0)).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2048]), torch.Size([1, 2048]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_model = zsl.models.ZeroShot(visual_fe, semantic_unit)\n",
    "image_embed, semantic_embed = zs_model(\n",
    "    features.unsqueeze(0), torch.FloatTensor(semantic).unsqueeze(0))\n",
    "image_embed.size(), semantic_embed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2048]), torch.Size([64, 2048]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels, semantics = next(iter(train_dl))\n",
    "images_embeds, semantics_embeds = zs_model(features.to(device), \n",
    "                                           semantics.to(device))\n",
    "\n",
    "images_embeds.size(), semantics_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [p for p in zs_model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(parameters, 1e-4, weight_decay=9e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] [299/460] loss: 0.4748\n",
      "Epoch [0] [460/460] loss: 0.4499\n",
      "Validation accuracy: 0.2174 top_5_accuracy: 0.8322 loss: 0.5206\n",
      "Epoch [1] [299/460] loss: 0.3927\n",
      "Epoch [1] [460/460] loss: 0.3883\n",
      "Validation accuracy: 0.2709 top_5_accuracy: 0.8625 loss: 0.5146\n",
      "Epoch [2] [299/460] loss: 0.3771\n",
      "Epoch [2] [460/460] loss: 0.3737\n",
      "Validation accuracy: 0.2932 top_5_accuracy: 0.8606 loss: 0.5131\n",
      "Epoch [3] [299/460] loss: 0.3677\n",
      "Epoch [3] [460/460] loss: 0.3655\n",
      "Validation accuracy: 0.3029 top_5_accuracy: 0.8659 loss: 0.5123\n",
      "Epoch [4] [299/460] loss: 0.3623\n",
      "Epoch [4] [460/460] loss: 0.3599\n",
      "Validation accuracy: 0.3146 top_5_accuracy: 0.8705 loss: 0.5112\n",
      "Epoch [5] [299/460] loss: 0.3584\n",
      "Epoch [5] [460/460] loss: 0.3557\n",
      "Validation accuracy: 0.3249 top_5_accuracy: 0.8783 loss: 0.5113\n",
      "Epoch [6] [299/460] loss: 0.3534\n",
      "Epoch [6] [460/460] loss: 0.3527\n",
      "Validation accuracy: 0.3244 top_5_accuracy: 0.8771 loss: 0.5109\n",
      "Epoch [7] [299/460] loss: 0.3517\n",
      "Epoch [7] [460/460] loss: 0.3500\n",
      "Validation accuracy: 0.3215 top_5_accuracy: 0.8827 loss: 0.5093\n",
      "Epoch [8] [299/460] loss: 0.3490\n",
      "Epoch [8] [460/460] loss: 0.3480\n",
      "Validation accuracy: 0.3320 top_5_accuracy: 0.8880 loss: 0.5082\n",
      "Epoch [9] [299/460] loss: 0.3477\n",
      "Epoch [9] [460/460] loss: 0.3469\n",
      "Validation accuracy: 0.3239 top_5_accuracy: 0.8895 loss: 0.5078\n",
      "Epoch [10] [299/460] loss: 0.3475\n",
      "Epoch [10] [460/460] loss: 0.3456\n",
      "Validation accuracy: 0.3137 top_5_accuracy: 0.8961 loss: 0.5081\n",
      "Epoch [11] [299/460] loss: 0.3445\n",
      "Epoch [11] [460/460] loss: 0.3443\n",
      "Validation accuracy: 0.3200 top_5_accuracy: 0.8939 loss: 0.5083\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "semantic_repr = torch.FloatTensor(valid_ds.attr_matrix)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    zsl.engine.train_epoch(\n",
    "         model=zs_model, dl=train_dl, optimizer=optimizer, \n",
    "         epoch=epoch, print_freq=300, device=device)\n",
    "    \n",
    "    zsl.engine.evaluate(\n",
    "        model=zs_model, dl=valid_dl,\n",
    "        class_representations=semantic_repr, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37664bitpytorchcondacbce87b99faf42faa84e2858cb997327"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
